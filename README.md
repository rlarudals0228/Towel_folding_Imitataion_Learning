# ðŸ§º Towel Folding Imitation Learning  
### Tunable Terminal Condition Classification (TTCC) ê¸°ë°˜ ìž¥ê¸° ë¹„ì •í˜•ì²´ ì¡°ìž‘ ëª¨ë°©í•™ìŠµ

---

## ðŸ“˜ ê°œìš”  
ë³¸ í”„ë¡œì íŠ¸ëŠ” *ì™¸ë¶€ RGB-D ì¹´ë©”ë¼ ê¸°ë°˜ ì •ëŸ‰ì  ì‹œê° ì§€í‘œ**ë¥¼ í™œìš©í•´  ë¡œë´‡ì´ ìˆ˜ê±´ì„ **ìžìœ¨ì ìœ¼ë¡œ í‰íƒ„í™”(Flatten)í•˜ê³  ì ‘ê¸°(Fold)** í•˜ëŠ”  
**2ë‹¨ê³„ ëª¨ë°©í•™ìŠµ í”„ë ˆìž„ì›Œí¬**ë¥¼ êµ¬í˜„í•œ ì—°êµ¬ìž…ë‹ˆë‹¤.

ê¸°ì¡´ ì—°êµ¬ì²˜ëŸ¼ â€œì‹œê°„ì´ë‚˜ ë‹¨ìˆœ ì‹œê° í”¼ì²˜â€ê°€ ì•„ë‹ˆë¼  **ì •ëŸ‰ ì§€í‘œ(metric)** ë¥¼ ì´ìš©í•´ ê° ë‹¨ê³„ì˜ **ì¢…ë£Œ ì¡°ê±´ì„ ì‹¤ì‹œê°„ íŒë‹¨**í•˜ê³ ,  
ì´ë¥¼ ì¡°ì • ê°€ëŠ¥í•œ í˜•íƒœ(**Tunable Terminal Condition**)ë¡œ ì„¤ê³„í•œ ì ìž…ë‹ˆë‹¤.

> ðŸ§© ëª©í‘œ: ë¡œë´‡ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜ê±´ì˜ ìƒíƒœë¥¼ í‰ê°€í•˜ì—¬  
> â€˜ì•„ì§ íŽ´ì•¼ í•˜ëŠ”ê°€(FLATTEN)â€™ ë˜ëŠ” â€˜ì ‘ì„ ë•Œì¸ê°€(FOLD)â€™ë¥¼ ìŠ¤ìŠ¤ë¡œ íŒë‹¨  

---


## ðŸ§  Key Contributions
- **Two-Stage Imitation Learning**  
  - Stage 1 â€“ Flattening policy learned from teleoperation + DAgger corrections  
  - Stage 2 â€“ Folding policy learned from roughly flattened towel states
  - 
- **TTCC Model (Tunable Threshold Decision)**  
  - Real-time evaluation of towel geometry to determine transition timing  
  - Thresholds adjustable for different task environments (home vs industrial)
  - 
- **Integrated System (Vision + Control + Learning)**  
  - RealSense D415 (top view) + D405 (wrist view)  
  - ROS 2 Jazzy + ACT inference pipeline  
  - Compatible with OpenManipulator-Y hardware  

---

### ðŸ“Š ì •ëŸ‰ ì§€í‘œ (Quantitative Visual Metrics)
| ì§€í‘œ | ì„¤ëª… | ì˜ë¯¸ |
|------|------|------|
| **Rectangularity Fit (Rfit)** | ìˆ˜ê±´ ì™¸ê³½ì˜ ì‚¬ê°í˜• ì •í•©ë„ | 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í‰íƒ„ |
| **Height Std (Ïƒâ‚•)** | í‘œë©´ ë†’ì´ì˜ í‘œì¤€íŽ¸ì°¨ | ìž‘ì„ìˆ˜ë¡ ê· ì¼ |
| **Height Range (Î”h)** | í‘œë©´ ì „ì²´ì˜ ë†’ì´ ì°¨ì´ | ìž‘ì„ìˆ˜ë¡ í‰í‰ |

TTCC ëª¨ë¸ì€ ì´ ì„¸ ê°€ì§€ ì§€í‘œë¥¼ ìž„ê³„ê°’(threshold)ê³¼ ë¹„êµí•˜ì—¬ ìƒíƒœë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤:
- `FLATTEN`: ì•„ì§ í‰íƒ„í™” í•„ìš”  
- `FOLD`: ì ‘ê¸° ì •ì±…ìœ¼ë¡œ ì „í™˜  

---

## ðŸŽ›ï¸ ì¡°ì • ê°€ëŠ¥í•œ ìž„ê³„ê°’ (Tunable Thresholds)
| ì ìš© í™˜ê²½ | Rect Fit (> ) | Height Std (< mm) | Height Range (< mm) |
|------------|---------------|--------------------|---------------------|
| ì‚°ì—… í™˜ê²½ (ì—„ê²©) | 0.85 | 7 | 18 |
| ê°€ì •/ì‹¤í—˜ í™˜ê²½ (ì™„í™”) | 0.77 | 15 | 30 |

â†’ ì‚¬ìš©ìžëŠ” í™˜ê²½ê³¼ ëª©ì ì— ë”°ë¼ ì „í™˜ ê¸°ì¤€ ë¯¼ê°ë„ë¥¼ ì¡°ì •í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.  
ì˜ˆ: ê³µìž¥ í™˜ê²½ì€ ì •ë°€ ê¸°ì¤€, ì¼ë°˜ í™˜ê²½ì€ ì™„í™”ëœ ê¸°ì¤€ ì ìš©

---

### Development Environment 
- OS: Ubuntu 24.04 LTS (Detail: Linux ubuntu 6.11.0-25-generic #25~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 15 17:20:50 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)
- ROS2: Jazzy
- Python: 3.12.3

### Reference
- https://github.com/huggingface/lerobot
- https://github.com/ROBOTIS-GIT/open_manipulator

## 1. ëª¨ë°©í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘

### Terminal 1
```
ssh root@192.168.0.138
docker exec -it open_manipulator bash
source /workspace/colcon_ws/install/setup.bash
ros2 launch open_manipulator_bringup ai_teleoperation.launch.py
```

### Terminal 2
```
source /opt/ros/jazzy/setup.bash
ros2 launch realsense2_camera rs_launch.py config_file:="realsense_config.yaml"
```

### Terminal 3
```
source /opt/ros/jazzy/setup.bash
rqt
```

### Terminal 4
```
source /opt/ros/jazzy/setup.bash
cd ~/colcon_ws
source install/setup.bash
ros2 launch ros2_lerobot create_datasheet.launch.py
```

## 2. ìˆ˜ì§‘í•œ ë°ì´í„° train & evaluation

### Visualize
```
conda activate mani
python -m lerobot.scripts.visualize_dataset  
--repo-id omy_real  -- root /home/dam/colcon_ws/src/ros2_lerobot/demo_data/towel_folding -- episode- index 0
```

### Train & Evalaution
```
conda activate mani
python train.py 
python evaluation.py
```

## 3. ëª¨ë°©í•™ìŠµ ì‹¤í–‰

### Terminal 1
```
ssh root@192.168.0.138
docker exec -it open_manipulator bash
source /workspace/colcon_ws/install/setup.bash
ros2 launch open_manipulator_bringup ai_inference.launch.py
```

### Terminal 2 (D415 camera ON)
```
source /opt/ros/jazzy/setup.bash
ros2 launch realsense2_camera rs_launch.py \
  camera_name:=external_camera \
  device_type:=d415 \
  align_depth:=true \
  enable_color:=true \
  enable_depth:=true \
  pointcloud.enable:=true
```

### Termianl 3 (ìˆ˜ê±´ íƒì§€ ì‹¤í–‰)
```
cd colcon_ws
source /opt/ros/jazzy/setup.bash
source install/setup.bash
ros2 run ros2_lerobot realsense_towel_metrics -- \
  --color /camera/external_camera/color/image_raw \
  --depth /camera/external_camera/depth/image_rect_raw \
  --rect-thr 0.85 --std-thr-mm 7.0 --range-thr-mm 18.0
```

### Terminal 4 (D405 camera ON)
```
source /opt/ros/jazzy/setup.bash
ros2 launch realsense2_camera rs_launch.py \
  camera_name:=arm_camera \
  device_type:=d405 \
  align_depth:=true \
  enable_depth:=true \
  pointcloud.enable:=true
```

### Terminal 5
```
source /opt/ros/jazzy/setup.bash
source install/setup.bash
rqt
```

### Terminal 6
```
source /opt/ros/jazzy/setup.bash
cd ~/colcon_ws
source install/setup.bash
ros2 launch ros2_lerobot inference_service_towel.launch.py
```
## ðŸ“Š Results (ê²°ê³¼)

![Result_1](result/result_1.gif)
![Result_2](result/result_2.gif)
